{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf107739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generator import Generator\n",
    "from test_backendclient import TestBackendClient\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "# 기존 핸들러들 제거 (중복 방지)\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# 로깅 설정 추가 (콘솔 + 파일)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),  # 노트북 출력으로 로그 표시\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 루트 로거 레벨 설정\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "generator = Generator()\n",
    "backend_client = TestBackendClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495095cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "from models import ScenarioCreate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from test_backendclient import TestBackendClient\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# -------------------- 1. AgentState 및 중간 결과 정의 --------------------\n",
    "class ChunkAnalysisResult(BaseModel):\n",
    "    \"\"\"Map 단계에서 필터링된 중요 아티팩트 리스트\"\"\"\n",
    "    important_artifacts: List[dict] = Field(\n",
    "        description=\"정보유출과 관련된 중요한 아티팩트만 선별한 리스트. 각 아티팩트는 원본 데이터 구조 그대로 유지.\"\n",
    "    )\n",
    "    chunk_summary: str = Field(\n",
    "        description=\"이 청크에서 발견된 의심 활동을 한 문장으로 간단히 요약 (예: '악성 파일 다운로드 및 실행')\"\n",
    "    )\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    artifact_chunks: List[List[dict]]\n",
    "    current_chunk_index: int\n",
    "    intermediate_results: List[ChunkAnalysisResult]\n",
    "    final_report: ScenarioCreate | None\n",
    "    job_id: str\n",
    "    task_id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed364da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 아티팩트 로딩 및 청크 분할 --------------------\n",
    "def load_artifacts(task_id: str) -> List[dict]:\n",
    "    backend_client = TestBackendClient()\n",
    "    job_id = \"test+job_id\"\n",
    "    return backend_client.load_artifacts(task_id, job_id)\n",
    "\n",
    "def chunk_artifacts(artifacts: List[dict], chunk_size: int = 50) -> List[List[dict]]:\n",
    "    return [artifacts[i:i+chunk_size] for i in range(0, len(artifacts), chunk_size)]\n",
    "\n",
    "def pretty_print_scenario(scenario: ScenarioCreate):\n",
    "    \"\"\"시나리오 객체를 받아 가독성 좋은 보고서 형태로 출력합니다.\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"📜 시나리오 분석 보고서: {scenario.name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n[ 보고서 개요 ]\")\n",
    "    print(f\"  - {scenario.description}\")\n",
    "    \n",
    "    print(\"\\n[ 식별 정보 ]\")\n",
    "    print(f\"  - Job ID: {scenario.job_id}\")\n",
    "    print(f\"  - Task ID: {scenario.task_id}\")\n",
    "    \n",
    "    print(\"\\n[ 재구성된 공격 단계 (Timeline) ]\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if not scenario.steps:\n",
    "        print(\"  (분석된 단계가 없습니다.)\")\n",
    "    else:\n",
    "        # 시간 순서대로 정렬 (이미 정렬되어 있지만 안전장치)\n",
    "        sorted_steps = sorted(scenario.steps, key=lambda s: s.order_no)\n",
    "        \n",
    "        for step in sorted_steps:\n",
    "            # datetime 객체를 보기 좋은 문자열로 포맷팅\n",
    "            timestamp_str = step.timestamp.strftime('%Y-%m-%d %H:%M:%S') if step.timestamp else \"\"\n",
    "            \n",
    "            # 아티팩트 ID 리스트를 콤마로 구분된 문자열로 변환\n",
    "            artifacts_str = \", \".join(step.artifact_ids)\n",
    "            \n",
    "            print(f\"\\n▶ Step {step.order_no}: [{timestamp_str}]\")\n",
    "            print(f\"  - 내용: {step.description}\")\n",
    "            print(f\"  - 연관 아티팩트: [{artifacts_str}]\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 2. Map 단계: analyze_chunk --------------------\n",
    "llm_small = init_chat_model(\"google_genai:gemini-2.5-flash-lite\", temperature=0)\n",
    "llm_large = init_chat_model(\"google_genai:gemini-2.5-pro\", temperature=0)\n",
    "\n",
    "def analyze_chunk(state: AgentState):\n",
    "    \"\"\"\n",
    "    Small model을 사용하여 청크에서 중요한 아티팩트만 빠르게 필터링.\n",
    "    원본 데이터를 그대로 유지하여 Reduce 단계로 전달.\n",
    "    \"\"\"\n",
    "    chunk_idx = state[\"current_chunk_index\"]\n",
    "    artifact_chunks = state[\"artifact_chunks\"]\n",
    "    chunk = artifact_chunks[chunk_idx]\n",
    "\n",
    "    # 아티팩트를 간략하게 포맷 (small model용 - 토큰 절약)\n",
    "    artifacts_summary = []\n",
    "    for idx, artifact in enumerate(chunk):\n",
    "        # 핵심 정보만 추출 (summary가 없으므로 data에서 주요 정보 추출)\n",
    "        artifact_type = artifact.get('artifact_type', 'N/A')\n",
    "        collected_at = artifact.get('collected_at', 'N/A')\n",
    "        artifact_id = artifact.get('id', 'N/A')\n",
    "        \n",
    "        # data 필드에서 중요한 정보만 선별\n",
    "        data = artifact.get('data', {})\n",
    "        # data를 간략하게 요약 (너무 길면 토큰 낭비)\n",
    "        data_summary = {}\n",
    "        for key in ['file_name', 'file_path', 'process_name', 'command_line', \n",
    "                    'url', 'device_name', 'sender', 'receiver', 'subject']:\n",
    "            if key in data and data[key]:\n",
    "                data_summary[key] = str(data[key])[:100]  # 최대 100자로 제한\n",
    "        \n",
    "        artifacts_summary.append({\n",
    "            \"index\": idx,\n",
    "            \"type\": artifact_type,\n",
    "            \"collected_at\": collected_at,\n",
    "            \"key_data\": data_summary,  # summary 대신 data의 핵심 정보 사용\n",
    "            \"id\": artifact_id\n",
    "        })\n",
    "    \n",
    "    artifacts_text = json.dumps(artifacts_summary, ensure_ascii=False, indent=2)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"당신은 엄격한 보안 분석가입니다. \n",
    "**정보유출 시나리오에 직접적으로 연관된 아티팩트만** 선택하세요.\n",
    "\n",
    "**필터링 우선순위 (점수제):**\n",
    "\n",
    "🔴 HIGH (반드시 포함):\n",
    "- 외부로 파일 전송: messenger_file, email_attachment, usb_device\n",
    "- 민감 파일 접근: 회사 기밀, 개인정보 파일\n",
    "- 악성 도구 실행: 암호화, 압축, 삭제 도구\n",
    "\n",
    "🟡 MEDIUM (의심스러운 경우만):\n",
    "- 비정상 시간대 접근 (새벽 2-5시)\n",
    "- 대량 파일 처리\n",
    "- 시스템 로그 삭제 시도\n",
    "\n",
    "⚪ LOW (제외):\n",
    "- 일반 브라우저 방문\n",
    "- 정상 업무 파일 접근\n",
    "- 시스템 자동 생성 로그\n",
    "- 현재로부터 6개월 이전 데이터\n",
    "\n",
    "**선택 기준:**\n",
    "1. HIGH 우선순위에 해당하는가?\n",
    "2. MEDIUM + 추가 의심 요소 2개 이상?\n",
    "3. 아니면 제외\n",
    "\n",
    "**목표: 청크당 최대 5-10개만 선택** (전체의 10% 이하)\n",
    "\n",
    "**출력:**\n",
    "- important_indices: HIGH + 명확한 MEDIUM만 포함\n",
    "- chunk_summary: 선택한 이유를 명확히\"\"\"),\n",
    "        (\"human\", \"아티팩트 목록:\\n{artifacts_text}\\n\\n청크 크기: {chunk_size}개\\n목표 선택 개수: 최대 {max_select}개\")\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # 필터링 결과 (index 리스트) 받기\n",
    "    class FilterResult(BaseModel):\n",
    "        important_indices: List[int] = Field(description=\"중요한 아티팩트의 index 번호 리스트\")\n",
    "        chunk_summary: str = Field(description=\"청크의 간단한 요약 (한 문장)\")\n",
    "    \n",
    "    structured_llm = llm_small.with_structured_output(FilterResult)\n",
    "    filter_chain = prompt | structured_llm\n",
    "    \n",
    "    try:\n",
    "        # 청크 크기에 따라 최대 선택 개수 동적 계산\n",
    "        chunk_size = len(chunk)\n",
    "        max_select = max(5, chunk_size // 50)  # 최소 5개, 또는 2%\n",
    "        \n",
    "        filter_result = filter_chain.invoke({\n",
    "            \"artifacts_text\": artifacts_text,\n",
    "            \"chunk_size\": chunk_size,\n",
    "            \"max_select\": max_select\n",
    "        })\n",
    "        \n",
    "        # LLM이 None을 반환하거나 필수 필드가 없는 경우 처리\n",
    "        if filter_result is None or not hasattr(filter_result, 'important_indices'):\n",
    "            print(f\"⚠️  청크 {chunk_idx + 1}: LLM 응답 오류 - 빈 결과로 처리\")\n",
    "            important_artifacts = []\n",
    "            chunk_summary = \"분석 실패\"\n",
    "        else:\n",
    "            # 선택된 아티팩트의 원본 데이터 추출\n",
    "            important_artifacts = [\n",
    "                chunk[idx] for idx in filter_result.important_indices \n",
    "                if 0 <= idx < len(chunk)\n",
    "            ]\n",
    "            \n",
    "            # 유의미한 데이터가 없는 경우 처리\n",
    "            if not important_artifacts:\n",
    "                print(f\"⚠️  청크 {chunk_idx + 1}: 유의미한 데이터 없음 (스킵)\")\n",
    "                chunk_summary = \"관련성 없는 데이터\"\n",
    "            else:\n",
    "                chunk_summary = filter_result.chunk_summary\n",
    "                print(f\"✅ 청크 {chunk_idx + 1}: {len(important_artifacts)}개 중요 아티팩트 발견\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 청크 {chunk_idx + 1}: 분석 중 에러 발생 - {str(e)}\")\n",
    "        important_artifacts = []\n",
    "        chunk_summary = f\"분석 오류: {type(e).__name__}\"\n",
    "    \n",
    "    chunk_result = ChunkAnalysisResult(\n",
    "        important_artifacts=important_artifacts,\n",
    "        chunk_summary=chunk_summary\n",
    "    )\n",
    "\n",
    "    # 중간 결과 누적\n",
    "    new_results = state.get(\"intermediate_results\", []) + [chunk_result]\n",
    "    return {\n",
    "        \"current_chunk_index\": chunk_idx + 1,\n",
    "        \"intermediate_results\": new_results\n",
    "    }\n",
    "\n",
    "# -------------------- 3. Reduce 단계: synthesize_report --------------------\n",
    "def synthesize_report(state: AgentState):\n",
    "    \"\"\"\n",
    "    필터링된 중요 아티팩트들을 Large model로 정밀 분석하여 최종 보고서 생성.\n",
    "    \"\"\"\n",
    "    intermediate_results = state[\"intermediate_results\"]\n",
    "    job_id = state[\"job_id\"]\n",
    "    task_id = state[\"task_id\"]\n",
    "\n",
    "    # 모든 중요 아티팩트를 하나로 모으기\n",
    "    all_important_artifacts = []\n",
    "    chunk_summaries = []\n",
    "    \n",
    "    for idx, result in enumerate(intermediate_results, 1):\n",
    "        # 유의미한 데이터가 있는 청크만 포함\n",
    "        if result.important_artifacts:\n",
    "            chunk_summaries.append(f\"청크 {idx}: {result.chunk_summary}\")\n",
    "            all_important_artifacts.extend(result.important_artifacts)\n",
    "    \n",
    "    # 전체적으로 유의미한 데이터가 없는 경우 처리\n",
    "    if not all_important_artifacts:\n",
    "        print(\"\\n❌ 전체 청크에서 유의미한 데이터를 찾지 못했습니다.\")\n",
    "        # 빈 보고서 반환\n",
    "        return {\n",
    "            \"final_report\": ScenarioCreate(\n",
    "                name=\"분석 결과 없음\",\n",
    "                description=\"제공된 아티팩트에서 정보유출과 관련된 유의미한 데이터를 발견하지 못했습니다.\",\n",
    "                job_id=job_id,\n",
    "                task_id=task_id,\n",
    "                steps=[],\n",
    "                report_detail_id=None\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n📊 총 {len(all_important_artifacts)}개의 중요 아티팩트 발견\")\n",
    "    \n",
    "    # 전체 요약\n",
    "    chunks_overview = \"\\n\".join(chunk_summaries)\n",
    "    \n",
    "    # 아티팩트를 상세하게 포맷 (Large model은 토큰 여유 있음)\n",
    "    formatted_artifacts = []\n",
    "    for artifact in all_important_artifacts:\n",
    "        artifact_type = artifact.get('artifact_type', 'N/A')\n",
    "        artifact_id = artifact.get('id', 'N/A')\n",
    "        collected_at = artifact.get('collected_at', 'N/A')\n",
    "        \n",
    "        # data 필드 전체 포함 (Large model은 상세 분석 가능)\n",
    "        data_details = json.dumps(artifact.get('data', {}), ensure_ascii=False, indent=2)\n",
    "        \n",
    "        formatted_string = (\n",
    "            f\"[ID: {artifact_id}]\\n\"\n",
    "            f\"  유형: {artifact_type}\\n\"\n",
    "            f\"  데이터:\\n{data_details}\"\n",
    "        )\n",
    "        formatted_artifacts.append(formatted_string)\n",
    "    \n",
    "    artifacts_detail = \"\\n\\n\".join(formatted_artifacts)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"당신은 내부정보 유출 사고 분석 및 보고서 작성 전문가입니다.\n",
    "\n",
    "**현재 상황:**\n",
    "여러 청크에서 필터링된 아티팩트들이 제공되었습니다.\n",
    "각 청크의 간단한 요약:\n",
    "{chunks_overview}\n",
    "\n",
    "**당신의 임무:**\n",
    "제공된 모든 아티팩트의 원본 데이터를 면밀히 분석하여,\n",
    "**논리적인 행위 단위**로 재구성된 정보유출 시나리오 보고서를 작성하세요.\n",
    "\n",
    "**보고서 작성 규칙:**\n",
    "\n",
    "1. **Step 생성 - 행위 중심:**\n",
    "   - 각 Step = 하나의 의미 있는 공격 행위\n",
    "   - 유사한 행위는 하나로 통합\n",
    "   - 시간 순서대로 정렬\n",
    "\n",
    "2. **artifact_ids:**\n",
    "   - 각 Step에 관련된 모든 아티팩트 ID 포함\n",
    "   - ID는 [ID: xxx] 형식으로 표시됨\n",
    "\n",
    "3. **timestamp:**\n",
    "   - \"수집 시각\" 필드에서 추출\n",
    "   - ISO 8601 형식 (예: \"2025-09-23T04:55:59\")\n",
    "   - 여러 아티팩트를 통합한 경우 가장 이른 시간 사용\n",
    "   - 알 수 없으면 null\n",
    "\n",
    "4. **description:**\n",
    "   - 중학생도 이해할 수 있게 작성\n",
    "   - \"누가/무엇을/왜/어떻게\" 명확히 설명\n",
    "\n",
    "5. **전체 보고서:**\n",
    "   - name: 간결한 제목 (15자 내외)\n",
    "   - description: 전체 흐름 요약 (2-3문장)\n",
    "\n",
    "**메타데이터:**\n",
    "- job_id: {job_id}\n",
    "- task_id: {task_id}\n",
    "\n",
    "**출력 형식:**\n",
    "{{{{\n",
    "  \"name\": \"악성 파일 유포 및 정보 유출\",\n",
    "  \"description\": \"전체 시나리오 요약...\",\n",
    "  \"job_id\": \"{job_id}\",\n",
    "  \"task_id\": \"{task_id}\",\n",
    "  \"steps\": [\n",
    "    {{{{\n",
    "      \"order_no\": 1,\n",
    "      \"timestamp\": \"2025-09-23T04:55:59\",\n",
    "      \"description\": \"행위 설명...\",\n",
    "      \"artifact_ids\": [\"id1\", \"id2\", ...]\n",
    "    }}}}\n",
    "  ]\n",
    "}}}}\"\"\"),\n",
    "        (\"human\", \"필터링된 중요 아티팩트:\\n\\n{artifacts_detail}\")\n",
    "    ])\n",
    "    \n",
    "    # Large model 사용 (정확한 분석)\n",
    "    load_dotenv(\"../.env\")\n",
    "    structured_llm = llm_large.with_structured_output(ScenarioCreate)\n",
    "    synth_chain = prompt | structured_llm\n",
    "\n",
    "    final_report = synth_chain.invoke({\"artifacts_detail\": artifacts_detail})\n",
    "\n",
    "    return {\"final_report\": final_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c192018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 4. 제어 흐름: router --------------------\n",
    "def router(state: AgentState):\n",
    "    if state[\"current_chunk_index\"] < len(state[\"artifact_chunks\"]):\n",
    "        return \"analyze_chunk\"\n",
    "    else:\n",
    "        return \"synthesize_report\"\n",
    "\n",
    "# -------------------- 5. 그래프 구성 및 실행 --------------------\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# 그래프 정의\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"analyze_chunk\", analyze_chunk)\n",
    "workflow.add_node(\"synthesize_report\", synthesize_report)\n",
    "workflow.set_entry_point(\"analyze_chunk\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_chunk\",\n",
    "    router,\n",
    "    {\n",
    "        \"analyze_chunk\": \"analyze_chunk\",\n",
    "        \"synthesize_report\": \"synthesize_report\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"synthesize_report\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c89dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b630ba4",
   "metadata": {},
   "source": [
    "## 청크 사이즈 최적화 가이드 (10만 개 아티팩트 기준)\n",
    "\n",
    "### 문제점:\n",
    "- 청크 100개 → 1000번의 LLM 호출 → 너무 느리고 비용 많이 발생\n",
    "- Map 단계에서 Small Model이지만 호출 횟수가 많으면 비효율적\n",
    "\n",
    "### 권장 청크 사이즈:\n",
    "\n",
    "**1. 모델별 토큰 제한 고려**\n",
    "- Gemini 2.5 Flash Lite: 입력 토큰 ~100만 (매우 큼)\n",
    "- 아티팩트 1개당 요약 형태 약 200-500 토큰\n",
    "- **권장: 500-1000개/청크** → 총 100-200번 호출\n",
    "\n",
    "**2. 실용적인 청크 사이즈 결정:**\n",
    "```python\n",
    "total_artifacts = 100_000\n",
    "\n",
    "# 옵션 A: 빠른 처리 (추천)\n",
    "chunk_size = 1000  # → 100번 Map 호출\n",
    "# 장점: 빠름, 필터링 효과 좋음\n",
    "# 단점: 청크당 토큰 사용량 증가\n",
    "\n",
    "# 옵션 B: 균형잡힌 처리\n",
    "chunk_size = 500   # → 200번 Map 호출\n",
    "# 장점: 안정적, 토큰 관리 용이\n",
    "# 단점: Map 호출 횟수 증가\n",
    "\n",
    "# 옵션 C: 매우 큰 청크 (대담한 선택)\n",
    "chunk_size = 2000  # → 50번 Map 호출\n",
    "# 장점: 최소 호출 횟수\n",
    "# 단점: 토큰 한계 근접 시 에러 가능\n",
    "```\n",
    "\n",
    "**3. 비용 및 시간 비교 (10만 개 기준):**\n",
    "| 청크 사이즈 | Map 호출 | 예상 시간 | API 비용 (대략) |\n",
    "|----------|---------|---------|--------------|\n",
    "| 100      | 1000번  | ~30분   | $$$$         |\n",
    "| 500      | 200번   | ~7분    | $$           |\n",
    "| 1000     | 100번   | ~4분    | $            |\n",
    "| 2000     | 50번    | ~2분    | $ (최저)      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 청크 사이즈 결정 함수\n",
    "def calculate_optimal_chunk_size(total_artifacts: int, target_chunks: int = 100) -> int:\n",
    "    \"\"\"\n",
    "    아티팩트 총 개수에 따라 최적의 청크 사이즈 계산\n",
    "    \n",
    "    Args:\n",
    "        total_artifacts: 전체 아티팩트 개수\n",
    "        target_chunks: 목표 청크 개수 (기본 100개)\n",
    "        \n",
    "    Returns:\n",
    "        최적화된 청크 사이즈\n",
    "    \"\"\"\n",
    "    # 목표 청크 개수로 나눈 값\n",
    "    calculated_size = total_artifacts // target_chunks\n",
    "    \n",
    "    # 최소/최대 제한 설정\n",
    "    min_chunk_size = 500   # 너무 작으면 비효율\n",
    "    max_chunk_size = 2000  # 너무 크면 토큰 초과 위험\n",
    "    \n",
    "    # 범위 내로 조정\n",
    "    optimal_size = max(min_chunk_size, min(calculated_size, max_chunk_size))\n",
    "    \n",
    "    # 실제 청크 개수 계산\n",
    "    actual_chunks = (total_artifacts + optimal_size - 1) // optimal_size\n",
    "    \n",
    "    print(f\"📊 청크 사이즈 최적화 결과:\")\n",
    "    print(f\"  - 전체 아티팩트: {total_artifacts:,}개\")\n",
    "    print(f\"  - 청크 사이즈: {optimal_size}개\")\n",
    "    print(f\"  - 예상 청크 개수: {actual_chunks}개\")\n",
    "    print(f\"  - Map 단계 LLM 호출: {actual_chunks}번\")\n",
    "    print(f\"  - 예상 처리 시간: ~{actual_chunks * 2.5:.0f}초 (약 {actual_chunks * 2.5 / 60:.1f}분)\")\n",
    "    \n",
    "    return optimal_size\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "total = len(artifacts) if 'artifacts' in locals() else 100000\n",
    "optimal_chunk_size = calculate_optimal_chunk_size(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da54586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화된 실행 버전\n",
    "from test_artifact_maker import make_test_artifacts\n",
    "\n",
    "task_id = \"session-20251002-052932-151e52e9\"\n",
    "job_id = \"test+job_id\"\n",
    "\n",
    "print(\"🔄 아티팩트 생성 중...\")\n",
    "artifacts = make_test_artifacts(task_id, limit=1000)\n",
    "# artifacts = make_test_artifacts(task_id)\n",
    "\n",
    "print(f\"\\n✅ 총 {len(artifacts):,}개 아티팩트 로드 완료\")\n",
    "\n",
    "# 동적으로 최적 청크 사이즈 계산\n",
    "optimal_chunk_size = calculate_optimal_chunk_size(len(artifacts), target_chunks=100)\n",
    "\n",
    "# 청크 분할\n",
    "artifact_chunks = chunk_artifacts(artifacts, chunk_size=optimal_chunk_size)\n",
    "\n",
    "print(f\"\\n🚀 분석 시작...\")\n",
    "initial_state = {\n",
    "    \"artifact_chunks\": artifact_chunks,\n",
    "    \"current_chunk_index\": 0,\n",
    "    \"intermediate_results\": [],\n",
    "    \"final_report\": None,\n",
    "    \"job_id\": job_id,\n",
    "    \"task_id\": task_id\n",
    "}\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "recursion_limit = len(artifact_chunks) + 10\n",
    "final_state = app.invoke(initial_state, config={\"recursion_limit\": recursion_limit})\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n⏱️  총 처리 시간: {elapsed_time:.1f}초 ({elapsed_time/60:.1f}분)\")\n",
    "print(f\"📊 처리된 청크: {len(artifact_chunks)}개\")\n",
    "print(f\"🔍 필터링된 중요 아티팩트: {sum(len(r.important_artifacts) for r in final_state['intermediate_results'])}개\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- 📋 최종 분석 결과 ---\")\n",
    "print(\"=\"*80)\n",
    "pretty_print_scenario(final_state[\"final_report\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
