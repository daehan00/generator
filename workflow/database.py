"""
ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ í•¨ìˆ˜ë“¤
- ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •ì€ í•œ ê³³ì—ì„œ ê´€ë¦¬ (VectorDBConfig)
- Factory Patternìœ¼ë¡œ ì‰½ê²Œ DB êµì²´ ê°€ëŠ¥
- ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ë©”íƒ€ë°ì´í„° ìµœì†Œí™”
"""
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from pathlib import Path
from datetime import datetime, date
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.vectorstores import VectorStore
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from chromadb.config import Settings as ChromaSettings


# --------------------------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# --------------------------------------------------------------------------

def convert_datetime_to_str(obj: Any) -> Any:
    """
    ì¬ê·€ì ìœ¼ë¡œ ê°ì²´ ë‚´ì˜ ëª¨ë“  datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.
    
    Args:
        obj: ë³€í™˜í•  ê°ì²´ (dict, list, datetime ë“±)
    
    Returns:
        datetimeì´ ë¬¸ìì—´ë¡œ ë³€í™˜ëœ ê°ì²´
    """
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {key: convert_datetime_to_str(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_datetime_to_str(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_datetime_to_str(item) for item in obj)
    else:
        return obj


def datetime_to_timestamp(dt: Any) -> Optional[float]:
    """
    Datetime ê°ì²´ë¥¼ UTC íƒ€ì„ìŠ¤íƒ¬í”„(ì´ˆ ë‹¨ìœ„)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        dt: datetime ê°ì²´, ISO í˜•ì‹ ë¬¸ìì—´, ë˜ëŠ” pandas Timestamp
    
    Returns:
        float: UTC íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ˆ ë‹¨ìœ„), ë³€í™˜ ì‹¤íŒ¨ ì‹œ None
    """
    if dt is None:
        return None
    
    try:
        # pandas Timestamp ì²˜ë¦¬
        if hasattr(dt, 'timestamp'):  # pandas.TimestampëŠ” timestamp() ë©”ì„œë“œê°€ ìˆìŒ
            return float(dt.timestamp())
        
        if isinstance(dt, str):
            # ìŠ¬ë˜ì‹œ êµ¬ë¶„ìë¥¼ ëŒ€ì‹œë¡œ ë³€ê²½ (ì˜ˆ: '2025/06/26 11:45:37.500' -> '2025-06-26 11:45:37.500')
            dt = dt.replace('/', '-')
            
            # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                # ISO í˜•ì‹ ì‹œë„
                dt = datetime.fromisoformat(dt.replace('Z', '+00:00'))
            except ValueError:
                # strptimeìœ¼ë¡œ íŒŒì‹± ì‹œë„
                from dateutil import parser
                dt = parser.parse(dt)
        
        if isinstance(dt, datetime):
            # UTC íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë³€í™˜
            return dt.timestamp()
        elif isinstance(dt, date):
            # dateë¥¼ datetimeìœ¼ë¡œ ë³€í™˜ í›„ íƒ€ì„ìŠ¤íƒ¬í”„
            dt = datetime.combine(dt, datetime.min.time())
            return dt.timestamp()
        
        return None
    except Exception as e:
        print(f"  âš ï¸  Datetime ë³€í™˜ ì‹¤íŒ¨: {e} (ê°’: {dt})")
        return None


def timestamp_to_datetime(ts: Optional[float]) -> Optional[str]:
    """
    UTC íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        ts: UTC íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ˆ ë‹¨ìœ„)
    
    Returns:
        str: ISO í˜•ì‹ ë¬¸ìì—´, ë³€í™˜ ì‹¤íŒ¨ ì‹œ None
    """
    if ts is None:
        return None
    
    try:
        dt = datetime.fromtimestamp(ts)
        return dt.isoformat()
    except Exception as e:
        print(f"  âš ï¸  Timestamp ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None


# --------------------------------------------------------------------------
# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • (í•œ ê³³ì—ì„œë§Œ ìˆ˜ì •í•˜ë©´ ì „ì²´ ì ìš©)
# --------------------------------------------------------------------------

@dataclass
class VectorDBConfig:
    """ë²¡í„° DB ì„¤ì • - ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ì „ì²´ DB êµì²´ ê°€ëŠ¥"""
    db_type: str = "chroma"  # "chroma" | "pinecone" | "faiss" ë“±
    embedding_model: str = "gemini-embedding-001"
    embedding_provider: str = "google"  # "google" | "openai" | "huggingface"
    persist_directory: str = "./chroma"
    
    # Chroma ì „ìš© ì„¤ì •
    chroma_settings: ChromaSettings = field(default_factory=lambda: ChromaSettings(
        anonymized_telemetry=False,
        is_persistent=True
    ))
    
    def __post_init__(self):
        """Chroma ì„¤ì • ì´ˆê¸°í™”"""
        # persist_directoryë¥¼ settingsì— ë™ì ìœ¼ë¡œ ë°˜ì˜
        self.chroma_settings.persist_directory = self.persist_directory

    # ë‹¤ë¥¸ DB ì¶”ê°€ ì‹œ ì—¬ê¸°ì— ì„¤ì • ì¶”ê°€
    # pinecone_api_key: Optional[str] = None
    # pinecone_environment: Optional[str] = None


# --------------------------------------------------------------------------
# RAG ê²€ìƒ‰ ì œí•œ ì„¤ì • (í† í° ì œí•œ)
# --------------------------------------------------------------------------

# ğŸ”§ ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ì „ì²´ ì‹œìŠ¤í…œì— ì ìš©ë¨
MAX_SEARCH_RESULTS = 300  # í•œ ë²ˆì— ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì•„í‹°íŒ©íŠ¸ ê°œìˆ˜


# ê¸°ë³¸ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
DEFAULT_DB_CONFIG = VectorDBConfig()


def get_embeddings(config: VectorDBConfig = DEFAULT_DB_CONFIG):
    """
    ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ ì„ë² ë”© ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        config: ë²¡í„° DB ì„¤ì •
    
    Returns:
        ì„ë² ë”© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
    """
    if config.embedding_provider == "google":
        return GoogleGenerativeAIEmbeddings(model=config.embedding_model)
    elif config.embedding_provider == "openai":
        from langchain_openai import OpenAIEmbeddings
        return OpenAIEmbeddings(model=config.embedding_model)
    # ë‹¤ë¥¸ provider ì¶”ê°€ ê°€ëŠ¥
    else:
        raise ValueError(f"Unknown embedding provider: {config.embedding_provider}")


def create_vectorstore(
    collection_name: str,
    config: VectorDBConfig = DEFAULT_DB_CONFIG
) -> VectorStore:
    """
    ì„¤ì •ì— ë”°ë¼ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ThreadPoolExecutor í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ë™ì‘í•˜ë„ë¡ PersistentClientë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        config: ë²¡í„° DB ì„¤ì •
    
    Returns:
        VectorStore ì¸ìŠ¤í„´ìŠ¤
    """
    embeddings = get_embeddings(config)
    
    if config.db_type == "chroma":
        import chromadb
        
        # ThreadPoolExecutor í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ë™ì‘í•˜ë„ë¡ chromadb.PersistentClient ì§ì ‘ ì‚¬ìš©
        client = chromadb.PersistentClient(
            path=config.persist_directory,
            settings=config.chroma_settings
        )
        
        return Chroma(
            client=client,
            collection_name=collection_name,
            embedding_function=embeddings
        )
    elif config.db_type == "pinecone":
        # from langchain_pinecone import PineconeVectorStore
        # return PineconeVectorStore(...)
        raise NotImplementedError("Pinecone support not yet implemented")
    elif config.db_type == "faiss":
        # from langchain_community.vectorstores import FAISS
        # return FAISS(...)
        raise NotImplementedError("FAISS support not yet implemented")
    else:
        raise ValueError(f"Unknown db_type: {config.db_type}")


# --------------------------------------------------------------------------
# ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í•¨ìˆ˜
# --------------------------------------------------------------------------


def save_to_chroma(
    artifacts: List[dict],
    collection_name: str = "filtered_artifacts",
    config: VectorDBConfig = DEFAULT_DB_CONFIG
) -> Dict:
    """
    í•„í„°ë§ëœ ì•„í‹°íŒ©íŠ¸ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    ë©”íƒ€ë°ì´í„° ìµœì†Œí™”: IDì™€ í•„í„°ë§ìš© ì •ë³´ë§Œ ì €ì¥, ë°ì´í„°ëŠ” page_contentì— í…ìŠ¤íŠ¸ë¡œ ì €ì¥
    
    Args:
        artifacts: ì €ì¥í•  ì•„í‹°íŒ©íŠ¸ ë¦¬ìŠ¤íŠ¸
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        config: ë²¡í„° DB ì„¤ì •
    
    Returns:
        Dict: {"data_save_status": "success" | "failure", "message": str, "count": int}
    """
    try:
        if not artifacts:
            return {
                "data_save_status": "success",
                "message": "ì €ì¥í•  ì•„í‹°íŒ©íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "count": 0
            }
        
        print(f"--- ğŸ’¾ {config.db_type.upper()} DBì— {len(artifacts)}ê°œ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì¤‘... ---")
        
        # 1. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        embeddings = get_embeddings(config)
        
        # 2. ì•„í‹°íŒ©íŠ¸ë¥¼ Documentë¡œ ë³€í™˜
        documents = []
        
        for idx, artifact in enumerate(artifacts):
            # ì•„í‹°íŒ©íŠ¸ì˜ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
            artifact_type = artifact.get('artifact_type', 'unknown')
            artifact_id = artifact.get('id', f'artifact_{idx}')
            source = artifact.get('source', 'unknown')
            data = convert_datetime_to_str(artifact.get('data', {}))
            collected_at = convert_datetime_to_str(artifact.get('collected_at', None))
            
            # ğŸ”¹ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ìƒì„± (íƒ€ì… + data í•„ë“œë“¤)
            # ì˜ˆ: "Type: usb_files\ndevice_name: Samsung Galaxy S10\nserial_number: SM_G975F..."
            content_parts = [f"Type: {artifact_type}"]
            for key, value in data.items():
                if value:  # Noneì´ë‚˜ ë¹ˆ ë¬¸ìì—´ ì œì™¸
                    # datetime ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ í…ìŠ¤íŠ¸ì— í¬í•¨
                    if isinstance(value, (datetime, date)):
                        content_parts.append(f"{key}: {value.isoformat()}")
                    else:
                        content_parts.append(f"{key}: {value}")
            
            page_content = "\n".join(content_parts)
            
            # ğŸ”¹ ë©”íƒ€ë°ì´í„°ëŠ” ìµœì†Œí•œë§Œ ì €ì¥ (IDì™€ ê²€ìƒ‰ í•„í„°ìš© ì •ë³´ë§Œ)
            # datetimeì€ íƒ€ì„ìŠ¤íƒ¬í”„(ìˆ«ì)ë¡œ ì €ì¥í•˜ì—¬ Chroma DB í•„í„°ë§ ê°€ëŠ¥í•˜ê²Œ í•¨
            datetime_timestamp = datetime_to_timestamp(collected_at)
            
            metadata = {
                "artifact_id": artifact_id,
                "artifact_type": artifact_type,
                "source": source,
                "datetime": collected_at,  # ISO ë¬¸ìì—´ (ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œìš©)
                "timestamp": datetime_timestamp,  # íƒ€ì„ìŠ¤íƒ¬í”„ (í•„í„°ë§ìš©)
                "index": idx
            }
            
            documents.append(
                Document(page_content=page_content, metadata=metadata)
            )
        
        # 3. ë²¡í„° DBì— ì €ì¥ (DB íƒ€ì…ì— ë”°ë¼ ìë™ ì„ íƒ)
        if config.db_type == "chroma":
            # ğŸ”¹ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬: 5,000ê°œì”© ë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ ì €ì¥
            BATCH_SIZE = 5000
            total_docs = len(documents)
            
            if total_docs <= BATCH_SIZE:
                # 5,000ê°œ ì´í•˜ë©´ í•œ ë²ˆì— ì €ì¥
                vectorstore = Chroma.from_documents(
                    documents=documents,
                    embedding=embeddings,
                    collection_name=collection_name,
                    persist_directory=config.persist_directory
                )
                print(f"  âœ… {total_docs}ê°œ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ")
            else:
                # 5,000ê°œ ì´ˆê³¼ ì‹œ ë°°ì¹˜ ì €ì¥
                print(f"  ğŸ“¦ ëŒ€ìš©ëŸ‰ ë°ì´í„° ê°ì§€: {total_docs:,}ê°œë¥¼ {BATCH_SIZE:,}ê°œì”© ë°°ì¹˜ ì €ì¥")
                
                # ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
                first_batch = documents[:BATCH_SIZE]
                vectorstore = Chroma.from_documents(
                    documents=first_batch,
                    embedding=embeddings,
                    collection_name=collection_name,
                    persist_directory=config.persist_directory
                )
                print(f"     âœ“ ë°°ì¹˜ 1/{(total_docs + BATCH_SIZE - 1) // BATCH_SIZE}: {len(first_batch):,}ê°œ ì €ì¥ ì™„ë£Œ")
                
                # ë‚˜ë¨¸ì§€ ë°°ì¹˜ ì¶”ê°€
                for batch_idx in range(BATCH_SIZE, total_docs, BATCH_SIZE):
                    batch_num = (batch_idx // BATCH_SIZE) + 1
                    batch_docs = documents[batch_idx:batch_idx + BATCH_SIZE]
                    
                    vectorstore.add_documents(batch_docs)
                    print(f"     âœ“ ë°°ì¹˜ {batch_num}/{(total_docs + BATCH_SIZE - 1) // BATCH_SIZE}: {len(batch_docs):,}ê°œ ì €ì¥ ì™„ë£Œ")
                
                print(f"  âœ… ì „ì²´ {total_docs:,}ê°œ ì•„í‹°íŒ©íŠ¸ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ")
        else:
            raise NotImplementedError(f"{config.db_type} ì €ì¥ ë¯¸êµ¬í˜„")
        
        print(f"  ğŸ“ ìœ„ì¹˜: {config.persist_directory}/{collection_name}")
        
        return {
            "data_save_status": "success",
            "message": f"{len(documents)}ê°œ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ",
            "count": len(documents),
            "collection_name": collection_name,  # RAG toolì—ì„œ ì‚¬ìš©
            "db_config": {  # RAG toolì´ DB ì¬ìƒì„±ì— í•„ìš”í•œ ì •ë³´
                "db_type": config.db_type,
                "embedding_model": config.embedding_model,
                "embedding_provider": config.embedding_provider,
                "persist_directory": config.persist_directory
            }
        }
        
    except Exception as e:
        error_msg = f"ë²¡í„° DB ì €ì¥ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}"
        print(f"  âŒ {error_msg}")
        
        return {
            "data_save_status": "failure",
            "message": error_msg,
            "count": 0
        }


def save_data_node(state) -> Dict[str, Any]:
    """
    ì›Œí¬í”Œë¡œìš° ë…¸ë“œ: í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    ë§¤ ì‘ì—…ë§ˆë‹¤ ìƒˆë¡œìš´ ë²¡í„° DBë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
    
    Args:
        state: AgentState (TypedDict)
    
    Returns:
        Dict: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (data_save_status, collection_name, db_config í¬í•¨)
    """
    print("--- ğŸ’¾ Node: í•„í„°ë§ëœ ë°ì´í„° ì €ì¥ ì‹œë„... ---")
    
    filtered_artifacts = state.get("filtered_artifacts", [])
    
    # ğŸ”¹ ê°„ë‹¨í•œ ê³ ì • ì»¬ë ‰ì…˜ ì´ë¦„ ì‚¬ìš© (Chroma ì´ë¦„ ê·œì¹™ ì¤€ìˆ˜)
    collection_name = "artifacts_collection"
    
    # ğŸ”¹ ë²¡í„° DB ì´ˆê¸°í™” (ì´ì „ ì»¬ë ‰ì…˜ ì‚­ì œ)
    try:
        import shutil
        chroma_path = Path(DEFAULT_DB_CONFIG.persist_directory) / collection_name
        if chroma_path.exists():
            shutil.rmtree(chroma_path)
            print(f"  ğŸ—‘ï¸  ì´ì „ ë²¡í„° DB ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸  ë²¡í„° DB ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
    
    # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì €ì¥ (ì—¬ê¸°ì„œ DB íƒ€ì… ë³€ê²½ ê°€ëŠ¥)
    result = save_to_chroma(
        artifacts=filtered_artifacts,
        collection_name=collection_name,
        config=DEFAULT_DB_CONFIG  # ì„¤ì • ë³€ê²½ ì‹œ ì—¬ê¸°ë§Œ ìˆ˜ì •
    )
    
    if result["data_save_status"] == "success":
        print(f"--- âœ… Node: ë°ì´í„° ì €ì¥ ì„±ê³µ ({result['count']}ê°œ) ---")
    else:
        print(f"--- âŒ Node: ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ ---")
    
    return result

