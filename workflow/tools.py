"""
RAG Agentê°€ ì‚¬ìš©í•˜ëŠ” ë„êµ¬(Tools) ì •ì˜
"""
from typing import Dict, Optional, Union
import logging

from langchain_core.tools import tool
from langchain_tavily import TavilySearch

from workflow.classes import StructuredQuery
from workflow.database import (
    VectorDBConfig,
    MAX_SEARCH_RESULTS,
    create_vectorstore,
    normalize_config,
    parse_document_content
)
from workflow.utils import (
    ChromaDBError,
    get_metadata_info,
    format_metadata_section,
    create_search_error_response,
    datetime_to_timestamp,
    llm_medium
)
from workflow.prompts import (
    QUERY_PLANNER_SYSTEM_PROMPT,
    QUERY_PLANNER_USER_PROMPT
)

logger = logging.getLogger(__name__)


# --------------------------------------------------------------------------
# ë„êµ¬ ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (State ì •ë³´ ì „ë‹¬ìš©)
# --------------------------------------------------------------------------

class ToolContext:
    """ë„êµ¬ê°€ State ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸"""
    collection_name: str = "artifacts_collection"
    db_config: Optional[Dict] = None
    
    @classmethod
    def set_context(cls, collection_name: str, db_config: Optional[Dict] = None):
        """Stateì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì„¤ì •"""
        cls.collection_name = collection_name
        cls.db_config = db_config
    
    @classmethod
    def get_collection_name(cls) -> str:
        """í˜„ì¬ ì»¬ë ‰ì…˜ ì´ë¦„ ë°˜í™˜"""
        return cls.collection_name
    
    @classmethod
    def get_db_config(cls) -> Optional[Dict]:
        """í˜„ì¬ DB ì„¤ì • ë°˜í™˜"""
        return cls.db_config


# --------------------------------------------------------------------------
# RAG Tools
# --------------------------------------------------------------------------


@tool
def query_planner_tool(natural_language_goal: str) -> Dict:
    """
    ìì—°ì–´ ê²€ìƒ‰ ëª©í‘œë¥¼ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ë¡œ ë³€í™˜ (ë‚´ë¶€ í•¨ìˆ˜)
    
    2ë‹¨ê³„ ê²€ìƒ‰ ì‹œìŠ¤í…œ:
    - 1ì°¨: ë©”íƒ€ë°ì´í„° í•„í„° (artifact_type, datetime)
    - 2ì°¨: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    
    Returns: StructuredQuery dict (query_text, filters, max_results, threshold)
    """
    logger.info("ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹œì‘: %s", natural_language_goal)
    
    # Stateì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    collection_name = ToolContext.get_collection_name()
    db_config = ToolContext.get_db_config()
    
    try:
        # ë©”íƒ€ë°ì´í„° ì •ë³´ ìˆ˜ì§‘
        metadata_info = get_metadata_info(collection_name, db_config)
        
        if metadata_info["total_count"] > 0:
            logger.info(
                "ë©”íƒ€ë°ì´í„°: %dê°œ ì•„í‹°íŒ©íŠ¸, %dê°œ íƒ€ì…",
                metadata_info["total_count"],
                len(metadata_info["artifact_types"])
            )
        else:
            logger.warning("ë©”íƒ€ë°ì´í„° ì—†ìŒ (ë¹ˆ DB)")
        
    except ChromaDBError as e:
        logger.debug("ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ (ë‚´ë¶€): %s", e)
        # ë©”íƒ€ë°ì´í„° ì—†ì´ ê³„ì† ì§„í–‰
        metadata_info = {
            "artifact_types": [],
            "datetime_range": {"earliest": None, "latest": None},
            "total_count": 0
        }
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    metadata_section = format_metadata_section(metadata_info)
    system_prompt = QUERY_PLANNER_SYSTEM_PROMPT.format(metadata_section=metadata_section)
    user_prompt = QUERY_PLANNER_USER_PROMPT.format(natural_language_goal=natural_language_goal)
    
    structured_llm = llm_medium.with_structured_output(StructuredQuery)
    
    try:
        response: StructuredQuery = structured_llm.invoke([  # type: ignore
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ])
        
        logger.info("ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: %s", response.query_text)
        return response.model_dump()
        
    except Exception as e:
        logger.warning("ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ì¿¼ë¦¬ë¡œ í´ë°±: %s", str(e))
        
        # í´ë°±: ê¸°ë³¸ ì¿¼ë¦¬ ë°˜í™˜
        fallback_query = StructuredQuery(
            query_text=natural_language_goal,
            filter_artifact_types=None,
            filter_datetime_start=None,
            filter_datetime_end=None,
            max_results=20,
            similarity_threshold=0.3
        )
        
        logger.info("ê¸°ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: %s", fallback_query.query_text)
        return fallback_query.model_dump()


@tool
def artifact_search_tool(
    structured_query: Dict,
    collection_name: Optional[str] = None,
    db_config: Union[None, dict, VectorDBConfig] = None
) -> Dict:
    """
    StructuredQueryë¡œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ (ë‚´ë¶€ í•¨ìˆ˜)
    
    2ë‹¨ê³„ ê²€ìƒ‰: ë©”íƒ€ë°ì´í„° í•„í„° â†’ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    Returns: Dict (results, query_info, total_count, limited)
    """
    logger.info("ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ ì‹œì‘")
    
    # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê¸°ë³¸ê°’ ê°€ì ¸ì˜¤ê¸°
    if collection_name is None:
        collection_name = ToolContext.get_collection_name()
    if db_config is None:
        db_config = ToolContext.get_db_config()
    
    try:
        # Config ì •ê·œí™”
        config = normalize_config(db_config)
        
        # ë²¡í„° DB ì¬ìƒì„± (stateì—ì„œ ì „ë‹¬ëœ ì„¤ì • ì‚¬ìš©)
        vectorstore = create_vectorstore(
            config=config,
            collection_name=collection_name
        )
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        query_text = structured_query.get("query_text", "")
        filter_types = structured_query.get("filter_artifact_types", [])
        filter_datetime_start = structured_query.get("filter_datetime_start")
        filter_datetime_end = structured_query.get("filter_datetime_end")
        
        # ê²€ìƒ‰ ê°œìˆ˜ ì œí•œ
        requested_max = structured_query.get("max_results", 300)
        max_results = max(1, min(requested_max, MAX_SEARCH_RESULTS))
        limited = max_results < requested_max
        similarity_threshold = structured_query.get("similarity_threshold", 0.5)
        
        if limited:
            logger.warning("max_results %dëŠ” %dë¡œ ì œí•œë©ë‹ˆë‹¤", requested_max, max_results)
        
        # ğŸ”¹ 1ì°¨ í•„í„°: ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„±
        filter_conditions = []
        
        # artifact_type í•„í„°
        if filter_types:
            filter_conditions.append({"artifact_type": {"$in": filter_types}})
        
        # datetime í•„í„° (timestampë¡œ ë³€í™˜)
        if filter_datetime_start:
            start_ts = datetime_to_timestamp(filter_datetime_start)
            if start_ts is not None:
                filter_conditions.append({"timestamp": {"$gte": start_ts}})
        
        if filter_datetime_end:
            end_ts = datetime_to_timestamp(filter_datetime_end)
            if end_ts is not None:
                filter_conditions.append({"timestamp": {"$lte": end_ts}})
        
        # ChromaDB í•„í„° êµ¬ì„±
        if not filter_conditions:
            metadata_filter = None
            logger.info("1ì°¨ í•„í„°: ì—†ìŒ (ì „ì²´ ê²€ìƒ‰)")
        elif len(filter_conditions) == 1:
            metadata_filter = filter_conditions[0]
            logger.info("1ì°¨ í•„í„° ì ìš©: %s", metadata_filter)
        else:
            metadata_filter = {"$and": filter_conditions}
            logger.info("1ì°¨ í•„í„° ì ìš© (ë‹¤ì¤‘ ì¡°ê±´): %dê°œ", len(filter_conditions))
        
        # ğŸ”¹ 2ì°¨ ê²€ìƒ‰: ìœ ì‚¬ë„ ê²€ìƒ‰ (1ì°¨ í•„í„° ê²°ê³¼ ëŒ€ìƒ)
        search_k = max_results * 2
        
        # ë™ê¸° ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰
        results_with_scores = vectorstore.similarity_search_with_score(
            query=query_text,
            k=search_k,
            filter=metadata_filter
        )
        
        # ê²€ìƒ‰ í†µê³„
        initial_count = len(results_with_scores)
        logger.info("1ì°¨ í•„í„° í†µê³¼: %dê°œ", initial_count)
        
        # ğŸ”¹ ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§ (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬í•¨)
        distance_threshold = 1.0 - similarity_threshold
        filtered_results = [
            (doc, score) 
            for doc, score in results_with_scores 
            if score <= distance_threshold
        ][:max_results]
        
        results = [doc for doc, score in filtered_results]
        filtered_count = len(results)
        
        logger.info("2ì°¨ í•„í„° (ìœ ì‚¬ë„ %.2f) í†µê³¼: %dê°œ", similarity_threshold, filtered_count)
        if limited:
            logger.warning("í† í° ì œí•œìœ¼ë¡œ %dê°œ â†’ %dê°œë¡œ ì œí•œë¨", requested_max, max_results)
        
        # Documentë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        artifacts = []
        for doc in results:
            artifact_dict = parse_document_content(doc.page_content)
            artifact_dict["id"] = doc.metadata.get("artifact_id", "unknown")
            artifact_dict["artifact_type"] = doc.metadata.get("artifact_type", "unknown")
            artifacts.append(artifact_dict)
        
        # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
        if limited:
            message = f"âœ… {filtered_count}ê°œ ê²€ìƒ‰ ì™„ë£Œ (ìš”ì²­: {requested_max}ê°œ â†’ í† í° ì œí•œìœ¼ë¡œ {max_results}ê°œë¡œ ì œí•œë¨)"
        elif filtered_count < requested_max:
            message = f"âœ… {filtered_count}ê°œ ê²€ìƒ‰ ì™„ë£Œ (ìœ ì‚¬ë„ ì„ê³„ê°’ {similarity_threshold}ë¡œ í•„í„°ë§)"
        else:
            message = f"âœ… {filtered_count}ê°œ ê²€ìƒ‰ ì™„ë£Œ"
        
        logger.info(message)
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            "artifacts": artifacts,
            "message": message,
            "metadata": {
                "requested": requested_max,
                "returned": filtered_count,
                "filtered_from": initial_count,
                "limited": limited,
                "threshold": similarity_threshold,
                "filter_types": filter_types or [],
                "filter_datetime_start": filter_datetime_start,
                "filter_datetime_end": filter_datetime_end,
                "filter_used": bool(filter_conditions)
            }
        }
        
    except ChromaDBError as e:
        logger.debug("ChromaDB ì˜¤ë¥˜ (ë‚´ë¶€): %s", str(e), exc_info=True)
        return create_search_error_response(f"ChromaDB ì˜¤ë¥˜: {str(e)}", structured_query)
    except Exception as e:
        logger.debug("ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨ (ë‚´ë¶€): %s - %s", type(e).__name__, str(e), exc_info=True)
        return create_search_error_response(f"ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}", structured_query)


@tool
def search_artifacts_tool(natural_language_goal: str) -> Dict:
    """
    ë””ì§€í„¸ í¬ë Œì‹ ì•„í‹°íŒ©íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (í†µí•© ë„êµ¬)
    
    [í†µí•© ê¸°ëŠ¥]
    - ìì—°ì–´ ê²€ìƒ‰ ëª©í‘œ ì…ë ¥ â†’ ìë™ìœ¼ë¡œ ìµœì í™”ëœ ì¿¼ë¦¬ ìƒì„± (AI ê¸°ë°˜)
    - 2ë‹¨ê³„ ê²€ìƒ‰ ì¦‰ì‹œ ì‹¤í–‰ (ë©”íƒ€ë°ì´í„° í•„í„° + ë²¡í„° ìœ ì‚¬ë„)
    - ê²€ìƒ‰ ê²°ê³¼ ì§ì ‘ ë°˜í™˜ (í•œ ë²ˆì˜ ë„êµ¬ í˜¸ì¶œë¡œ ì™„ë£Œ)
    
    [ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤]
    ë‚´ë¶€ 1ë‹¨ê³„: ì¿¼ë¦¬ ìµœì í™” (ìë™)
       - LLMì´ ê²€ìƒ‰ ëª©í‘œ ë¶„ì„
       - ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ìµœì  í•„í„° ìë™ ê²°ì •
       - artifact_type, datetime, í•„í„° ìƒì„±
    
    ë‚´ë¶€ 2ë‹¨ê³„: ì‹¤ì œ ê²€ìƒ‰ (ìë™)
       - 1ì°¨: ë©”íƒ€ë°ì´í„° í•„í„°ë§
       - 2ì°¨: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
       - ê²°ê³¼ ë°˜í™˜
    
    [ê²€ìƒ‰ íŒ]
    êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í• ìˆ˜ë¡ ì •í™•í•œ ê²°ê³¼:
    - "2024ë…„ 1ì›” 15ì¼ ì˜¤ì „ USBë¡œ ì „ì†¡ëœ ë¬¸ì„œ íŒŒì¼" âœ…
    - "ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ ê¸°ë¡ì—ì„œ .exe íŒŒì¼" âœ…
    - "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒŒì¼" âŒ (ë„ˆë¬´ ê´‘ë²”ìœ„)
    
    [ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°]
    - artifacts: ì‹¤ì œ ê²€ìƒ‰ëœ ì•„í‹°íŒ©íŠ¸ ë¦¬ìŠ¤íŠ¸
    - message: ê²€ìƒ‰ ì™„ë£Œ ë©”ì‹œì§€
    - metadata: ê²€ìƒ‰ í†µê³„ (ê°œìˆ˜, í•„í„° ì ìš© ì—¬ë¶€ ë“±)
    
    Args:
        natural_language_goal: êµ¬ì²´ì ì¸ ê²€ìƒ‰ ëª©í‘œ (ìì—°ì–´)
    
    Returns:
        Dict: {
            "artifacts": [
                {
                    "id": "artifact_001",
                    "artifact_type": "usb_files",
                    "device_name": "Samsung",
                    "file_name": "secret.pdf",
                    ...
                }
            ],
            "message": "18ê°œ ê²€ìƒ‰ ì™„ë£Œ",
            "metadata": {
                "requested": 20,
                "returned": 18,
                "filtered_from": 150,
                "limited": False,
                "threshold": 0.7,
                "filter_types": ["usb_files"]
            }
        }
    
    Examples:
        >>> search_artifacts_tool("USBë¡œ ì „ì†¡ëœ ê¸°ë°€ ë¬¸ì„œ")
        {'artifacts': [...], 'message': '5ê°œ ê²€ìƒ‰ ì™„ë£Œ'}
        
        >>> search_artifacts_tool("2024-01-15 ì˜¤ì „ ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ ê¸°ë¡")
        {'artifacts': [...], 'message': '12ê°œ ê²€ìƒ‰ ì™„ë£Œ'}
        
        >>> search_artifacts_tool("ì´ë ¥ì„œ ê´€ë ¨ ì›¹ì‚¬ì´íŠ¸ ì ‘ì† ê¸°ë¡")
        {'artifacts': [...], 'message': '8ê°œ ê²€ìƒ‰ ì™„ë£Œ'}
    
    Note:
        - ìµœëŒ€ 300ê°œ ê²°ê³¼ ì œí•œ
        - ê²€ìƒ‰ ê²°ê³¼ê°€ ì ìœ¼ë©´ ë” ê´‘ë²”ìœ„í•œ í‚¤ì›Œë“œë¡œ ì¬ì‹œë„ ê¶Œì¥
        - ì‹œê°„, íƒ€ì… í•„í„°ë¥¼ í¬í•¨í•˜ë©´ ê²€ìƒ‰ ì†ë„ ëŒ€í­ í–¥ìƒ
    """
    logger.info("=== í†µí•© ê²€ìƒ‰ ì‹¤í–‰ ===")
    
    # Step 1: ì¿¼ë¦¬ ìƒì„±
    logger.info("Step 1/2: ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ì¤‘...")
    try:
        query_result = query_planner_tool.invoke({"natural_language_goal": natural_language_goal})
        logger.info("ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.error("ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: %s", str(e), exc_info=True)
        return {
            "artifacts": [],
            "message": f"âŒ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}",
            "metadata": {"returned": 0}
        }
    
    # Step 2: ê²€ìƒ‰ ì‹¤í–‰
    logger.info("Step 2/2: ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ ì¤‘...")
    try:
        search_result = artifact_search_tool.invoke({
            "structured_query": query_result,
            "collection_name": None,
            "db_config": None
        })
        
        artifacts_count = len(search_result.get("artifacts", []))
        logger.info("í†µí•© ê²€ìƒ‰ ì™„ë£Œ: %dê°œ ë°œê²¬", artifacts_count)
        return search_result
        
    except Exception as e:
        logger.error("ê²€ìƒ‰ ì‹¤íŒ¨: %s", str(e), exc_info=True)
        return {
            "artifacts": [],
            "message": f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}",
            "metadata": {"returned": 0}
        }


# ì›¹ ê²€ìƒ‰ ë„êµ¬ (Tavily)
web_search_tool = TavilySearch(max_results=3)
web_search_tool.name = "web_search_tool"
web_search_tool.description = """
ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ë³´ì•ˆ ìœ„í˜‘, ê³µê²© ê¸°ë²•, CVE ì •ë³´ ë“± 
ì™¸ë¶€ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
"""


# ëª¨ë“  ë„êµ¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ export
agent_tools = [
    search_artifacts_tool,  # í†µí•© ê²€ìƒ‰ ë„êµ¬ (query_planner + artifact_search)
    web_search_tool
]
