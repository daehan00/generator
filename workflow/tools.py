"""
RAG Agentê°€ ì‚¬ìš©í•˜ëŠ” ë„êµ¬(Tools) ì •ì˜
"""
from typing import List, Dict, Optional
import asyncio
import nest_asyncio

from langchain_core.tools import tool
from langchain_tavily import TavilySearch

from workflow.classes import StructuredQuery
from common.utils import llm_medium
from workflow.database import (
    create_vectorstore, 
    DEFAULT_DB_CONFIG,
    MAX_SEARCH_RESULTS,  # ê²€ìƒ‰ ì œí•œ ìƒìˆ˜
    datetime_to_timestamp  # datetime â†’ timestamp ë³€í™˜ í•¨ìˆ˜
)
from workflow.prompts import (
    QUERY_PLANNER_SYSTEM_PROMPT,
    QUERY_PLANNER_USER_PROMPT
)

# ThreadPoolExecutor í™˜ê²½ì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
nest_asyncio.apply()


# --------------------------------------------------------------------------
# ë„êµ¬ ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (State ì •ë³´ ì „ë‹¬ìš©)
# --------------------------------------------------------------------------

class ToolContext:
    """ë„êµ¬ê°€ State ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸"""
    collection_name: str = "artifacts_collection"
    db_config: Optional[Dict] = None
    
    @classmethod
    def set_context(cls, collection_name: str, db_config: Optional[Dict] = None):
        """Stateì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì„¤ì •"""
        cls.collection_name = collection_name
        cls.db_config = db_config
    
    @classmethod
    def get_collection_name(cls) -> str:
        """í˜„ì¬ ì»¬ë ‰ì…˜ ì´ë¦„ ë°˜í™˜"""
        return cls.collection_name
    
    @classmethod
    def get_db_config(cls) -> Optional[Dict]:
        """í˜„ì¬ DB ì„¤ì • ë°˜í™˜"""
        return cls.db_config


# --------------------------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# --------------------------------------------------------------------------

def parse_page_content(page_content: str) -> Dict[str, str]:
    """
    Documentì˜ page_contentë¥¼ íŒŒì‹±í•˜ì—¬ data dictë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        page_content: "Type: usb_files\\ndevice_name: Samsung\\nfile_name: secret.pdf"
    
    Returns:
        {"device_name": "Samsung", "file_name": "secret.pdf"}
        (Typeì€ ì œì™¸, metadataì— ì´ë¯¸ ìˆìŒ)
    
    Example:
        >>> content = "Type: usb_files\\ndevice_name: Samsung Galaxy\\nfile_name: secret.pdf"
        >>> parse_page_content(content)
        {'device_name': 'Samsung Galaxy', 'file_name': 'secret.pdf'}
    """
    data = {}
    lines = page_content.strip().split('\n')
    
    for line in lines:
        if ':' in line and not line.startswith('Type:'):
            key, value = line.split(':', 1)
            data[key.strip()] = value.strip()
    
    return data


def get_metadata_info(collection_name: str, config=None) -> Dict:
    """
    ë²¡í„° DBì—ì„œ ë©”íƒ€ë°ì´í„° í†µê³„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    LLMì´ ììœ¨ì ìœ¼ë¡œ í•„í„°ë§ì„ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    ThreadPoolExecutor í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ë™ì‘í•˜ë„ë¡ chromadb.PersistentClientë¥¼ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        config: VectorDBConfig (Noneì´ë©´ DEFAULT_DB_CONFIG ì‚¬ìš©)
    
    Returns:
        {
            "artifact_types": ["usb_files", "browser_history", ...],
            "datetime_range": {
                "earliest": "2024-01-01T00:00:00",
                "latest": "2024-01-31T23:59:59"
            },
            "total_count": 1000
        }
    """
    try:
        if config is None:
            config = DEFAULT_DB_CONFIG
        
        # ThreadPoolExecutor í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ë™ì‘í•˜ë„ë¡ chromadb.PersistentClient ì§ì ‘ ì‚¬ìš©
        import chromadb
        
        client = chromadb.PersistentClient(
            path=config.persist_directory,
            settings=config.chroma_settings
        )
        
        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ)
        collection = client.get_collection(name=collection_name)
        
        # ëª¨ë“  ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_data = collection.get(include=["metadatas"])
        all_metadata = all_data.get("metadatas", [])
        
        if not all_metadata:
            return {
                "artifact_types": [],
                "datetime_range": {"earliest": None, "latest": None},
                "total_count": 0
            }
        
        # í†µê³„ ìˆ˜ì§‘
        artifact_types = set()
        datetimes = []
        
        for meta in all_metadata:
            if meta.get("artifact_type"):
                artifact_types.add(meta["artifact_type"])
            if meta.get("datetime"):
                datetimes.append(meta["datetime"])
        
        return {
            "artifact_types": sorted(list(artifact_types)),
            "datetime_range": {
                "earliest": min(datetimes) if datetimes else None,
                "latest": max(datetimes) if datetimes else None
            },
            "total_count": len(all_metadata)
        }
        
    except Exception as e:
        print(f"  âš ï¸  ë©”íƒ€ë°ì´í„° ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {
            "artifact_types": [],
            "datetime_range": {"earliest": None, "latest": None},
            "total_count": 0
        }


def format_metadata_section(metadata_info: dict) -> str:
    """
    ë©”íƒ€ë°ì´í„° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        metadata_info: get_metadata_info()ë¡œë¶€í„° ë°˜í™˜ëœ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    
    Returns:
        str: í¬ë§·íŒ…ëœ ë©”íƒ€ë°ì´í„° ì„¹ì…˜ ë¬¸ìì—´
    """
    total_count = metadata_info.get('total_count', 0)
    artifact_types = metadata_info.get('artifact_types', [])
    datetime_range = metadata_info.get('datetime_range', {})
    
    return f"""**ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„°:**
- ì „ì²´ ì•„í‹°íŒ©íŠ¸ ìˆ˜: {total_count:,}ê°œ
- ì‚¬ìš© ê°€ëŠ¥í•œ Artifact Types: {artifact_types}
- ì‹œê°„ ë²”ìœ„: {datetime_range.get('earliest')} ~ {datetime_range.get('latest')}"""


# --------------------------------------------------------------------------
# RAG Tools
# --------------------------------------------------------------------------


@tool
def query_planner_tool(natural_language_goal: str) -> Dict:
    """
    ë””ì§€í„¸ í¬ë Œì‹ ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ì„ ìœ„í•œ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    [ì¤‘ìš”] ì´ ë„êµ¬ëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤ì œ ê²€ìƒ‰ì€ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    
    [ì´ ë„êµ¬ì˜ ì—­í• ]
    - ìì—°ì–´ ê²€ìƒ‰ ëª©í‘œ -> êµ¬ì¡°í™”ëœ ì¿¼ë¦¬(StructuredQuery)ë¡œ ë³€í™˜
    - ìµœì ì˜ í•„í„° ì¡°í•© ìë™ ê²°ì • (AI ê¸°ë°˜)
    - ì‹¤ì œ ë°ì´í„° ê²€ìƒ‰ì€ í•˜ì§€ ì•ŠìŒ -> artifact_search_tool ì‚¬ìš© í•„ìš”
    
    [ì‘ì—… íë¦„]
    1. query_planner_tool() <- ì¿¼ë¦¬ ìƒì„± (ì´ ë„êµ¬)
       â†“ (StructuredQuery ë°˜í™˜)
    2. artifact_search_tool() <- ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
       â†“ (ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜)
    3. ê²°ê³¼ ë¶„ì„ ë° í™œìš©
    
    [ìƒì„±ë˜ëŠ” ì¿¼ë¦¬ êµ¬ì¡° - 2ë‹¨ê³„ ê²€ìƒ‰ ì‹œìŠ¤í…œ]
    
    1ë‹¨ê³„: 1ì°¨ í•„í„°ë§ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜ - ì„ íƒì )
       - artifact_type: íƒ€ì…ë³„ ì •í™• ë§¤ì¹­ (ì˜ˆ: usb_files, browser_history, prefetch_file)
       - datetime: ì‹œê°„ ë²”ìœ„ í•„í„°ë§ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
       -> ê²€ìƒ‰ ë²”ìœ„ë¥¼ ëŒ€í­ ì¶•ì†Œí•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ (ì „ì²´ 10,000ê°œ -> ìˆ˜ë°± ê°œ)
    
    2ë‹¨ê³„: 2ì°¨ ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ - í•„ìˆ˜)
       - ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ì •í™•í•œ ê²°ê³¼ ì¶”ì¶œ
       - similarity_thresholdë¡œ ì •í™•ë„ ì¡°ì ˆ
    
    [ê²€ìƒ‰ ëª©í‘œ ì‘ì„± íŒ]
    í•„í„°ë§ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë” êµ¬ì²´ì ì¸ ëª©í‘œë¥¼ ì„¤ì •í•˜ì„¸ìš”:
    
    ì¢‹ì€ ì˜ˆ:
    - "2024ë…„ 1ì›” 15ì¼ ì˜¤ì „ 9ì‹œ-12ì‹œ ì‚¬ì´ì— USBë¥¼ í†µí•´ ë‹¤ìš´ë¡œë“œëœ ì˜ì‹¬ íŒŒì¼ ì°¾ê¸°"
      -> datetime, artifact_type í•„í„° ëª¨ë‘ í™œìš© ê°€ëŠ¥
    - "ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ ê¸°ë¡ì—ì„œ .exe íŒŒì¼ ê²€ìƒ‰"
      -> artifact_type í•„í„° í™œìš©
    
    ë‚˜ìœ ì˜ˆ:
    - "íŒŒì¼ ì°¾ê¸°" -> ë„ˆë¬´ ê´‘ë²”ìœ„, í•„í„°ë§ ë¶ˆê°€
    
    [ìë™ ìµœì í™”]
    - ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„°ë¥¼ ìë™ ë¶„ì„í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œ í•„í„° í™•ì¸
    - LLMì´ ê²€ìƒ‰ ëª©í‘œì— ë§ëŠ” ìµœì ì˜ í•„í„° ì¡°í•© ììœ¨ ê²°ì •
    - ë¶ˆí™•ì‹¤í•œ ê²½ìš° í•„í„°ë§ ì—†ì´ ì „ì²´ ê²€ìƒ‰ (ì•ˆì „ëª¨ë“œ)
    
    Args:
        natural_language_goal: êµ¬ì²´ì ì¸ ê²€ìƒ‰ ëª©í‘œ (ì‹œê°„, íƒ€ì…, ì†ŒìŠ¤ ë“± í¬í•¨ ê¶Œì¥)
    
    Returns:
        Dict: ìµœì í™”ëœ StructuredQuery (ê²€ìƒ‰ ì¿¼ë¦¬ ê°ì²´, ì‹¤ì œ ë°ì´í„° ì•„ë‹˜!)
            - query_text: ë²¡í„° ê²€ìƒ‰ í‚¤ì›Œë“œ
            - filter_artifact_types: íƒ€ì… í•„í„° (Optional)
            - filter_datetime_start/end: ì‹œê°„ ë²”ìœ„ (Optional)
            - max_results: ë°˜í™˜ ê°œìˆ˜
            - similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
    
    Examples:
        >>> # Step 1: ì¿¼ë¦¬ ìƒì„± (ì´ ë„êµ¬)
        >>> query = query_planner_tool("2024-01-15 ì˜¤ì „ì— USBë¡œ ì „ì†¡ëœ ë¬¸ì„œ íŒŒì¼")
        >>> # queryëŠ” StructuredQuery ë”•ì…”ë„ˆë¦¬ (ì‹¤ì œ ë°ì´í„° ì•„ë‹˜!)
        
        >>> # Step 2: ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰ (artifact_search_tool)
        >>> results = artifact_search_tool(query, "artifacts_collection")
        >>> # resultsì— ì‹¤ì œ ê²€ìƒ‰ëœ ì•„í‹°íŒ©íŠ¸ í¬í•¨
        
        >>> # Source í¬í•¨ ê²€ìƒ‰
        >>> query_planner_tool("secretì´ í¬í•¨ëœ íŒŒì¼ ì°¾ê¸°")
        
        >>> # í•„í„° ì—†ì´ ì „ì²´ ê²€ìƒ‰
        >>> query_planner_tool("ì‹œìŠ¤í…œ ì „ì²´ì—ì„œ ì•”í˜¸í™” ê´€ë ¨ í™œë™")
    """
    print("--- ğŸ§  Tool: ê²€ìƒ‰ ì¿¼ë¦¬ ê³„íš ì¤‘ ---")
    
    # Stateì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    collection_name = ToolContext.get_collection_name()
    db_config = ToolContext.get_db_config()
    
    # 1. ë©”íƒ€ë°ì´í„° ì •ë³´ ìˆ˜ì§‘
    print("  ğŸ“Š ë©”íƒ€ë°ì´í„° ë¶„ì„ ì¤‘...")
    metadata_info = get_metadata_info(collection_name, db_config)
    
    if metadata_info["total_count"] > 0:
        print(f"  âœ… ë©”íƒ€ë°ì´í„° ë¶„ì„ ì™„ë£Œ:")
        print(f"     - ì „ì²´ ì•„í‹°íŒ©íŠ¸: {metadata_info['total_count']:,}ê°œ")
        print(f"     - Artifact Types: {len(metadata_info['artifact_types'])}ê°œ, {metadata_info['artifact_types']}")
        print(f"     - ì‹œê°„ ë²”ìœ„: {metadata_info['datetime_range']['earliest']} ~ {metadata_info['datetime_range']['latest']}")
    else:
        print(f"  âš ï¸  ë©”íƒ€ë°ì´í„° ì—†ìŒ (ë¹ˆ DB ë˜ëŠ” ì˜¤ë¥˜)")
    
    # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
    metadata_section = format_metadata_section(metadata_info)
    system_prompt = QUERY_PLANNER_SYSTEM_PROMPT.format(metadata_section=metadata_section)
    user_prompt = QUERY_PLANNER_USER_PROMPT.format(natural_language_goal=natural_language_goal)
    
    
    structured_llm = llm_medium.with_structured_output(StructuredQuery)
    
    try:
        response: StructuredQuery = structured_llm.invoke([  # type: ignore
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ])
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"  âœ… ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ:")
        print(f"     - query_text: {response.query_text}")
        print(f"     - 1ì°¨ í•„í„°:")
        print(f"       â€¢ artifact_types: {response.filter_artifact_types or '(í•„í„°ë§ ì—†ìŒ)'}")
        print(f"       â€¢ datetime: {response.filter_datetime_start or '(ì—†ìŒ)'} ~ {response.filter_datetime_end or '(ì—†ìŒ)'}")
        print(f"     - 2ì°¨ ê²€ìƒ‰:")
        print(f"       â€¢ max_results: {response.max_results}")
        print(f"       â€¢ similarity_threshold: {response.similarity_threshold}")
        
        return response.model_dump()
        
    except Exception as e:
        print(f"  âŒ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê¸°ë³¸ ì¿¼ë¦¬ ë°˜í™˜ (í•„í„°ë§ ì—†ìŒ)
        fallback_query = StructuredQuery(
            query_text=natural_language_goal,  # ì›ë³¸ ëª©í‘œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            filter_artifact_types=None,
            filter_datetime_start=None,
            filter_datetime_end=None,
            max_results=20,
            similarity_threshold=0.3
        )
        
        print(f"  ğŸ”„ ê¸°ë³¸ ì¿¼ë¦¬ë¡œ í´ë°±")
        return fallback_query.model_dump()


@tool
def artifact_search_tool(
    structured_query: Dict,
    collection_name: Optional[str] = None,
    db_config: Optional[Dict] = None
) -> Dict:
    """
    êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ë¡œ ë””ì§€í„¸ í¬ë Œì‹ ì•„í‹°íŒ©íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    [ì£¼ì˜] ì´ ë„êµ¬ëŠ” ì§ì ‘ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”!
    ë°˜ë“œì‹œ query_planner_toolì„ ë¨¼ì € í˜¸ì¶œí•˜ì—¬ ìµœì í™”ëœ ì¿¼ë¦¬ë¥¼ ìƒì„±í•œ í›„,
    ê·¸ ê²°ê³¼ë¥¼ ì´ ë„êµ¬ì— ì „ë‹¬í•˜ì„¸ìš”.
    
    [ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤]
    1ë‹¨ê³„: 1ì°¨ í•„í„°ë§ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
       - structured_queryì— í¬í•¨ëœ í•„í„° ì ìš©:
         * filter_artifact_types: íƒ€ì… í•„í„° (ì •í™• ì¼ì¹˜)
         * filter_datetime: ì‹œê°„ ë²”ìœ„ í•„í„° (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
       - ì „ì²´ ë°ì´í„°ì—ì„œ ê´€ë ¨ ìˆëŠ” ê²ƒë§Œ ì¶”ì¶œ (ì„±ëŠ¥ ìµœì í™”)
    
    2ë‹¨ê³„: 2ì°¨ ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜)
       - 1ì°¨ í•„í„° í†µê³¼í•œ ë°ì´í„°ì—ì„œ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê²€ìƒ‰
       - similarity_threshold ì ìš©í•˜ì—¬ ì •í™•ë„ ë³´ì¥
    
    [ê²€ìƒ‰ ê²°ê³¼]
    - ê° ì•„í‹°íŒ©íŠ¸ëŠ” ID, artifact_type, ì‹¤ì œ ë°ì´í„° í¬í•¨
    - ë©”íƒ€ë°ì´í„°ë¡œ ê²€ìƒ‰ í†µê³„ ì œê³µ (í•„í„°ë§ ì „í›„ ê°œìˆ˜ ë“±)
    
    
    Args:
        structured_query: query_planner_toolì´ ìƒì„±í•œ StructuredQuery (Dict í˜•íƒœ)
        collection_name: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ì´ë¦„ (ìƒëµ ì‹œ Stateì—ì„œ ìë™ ê°€ì ¸ì˜´)
        db_config: DB ì„¤ì • (ìƒëµ ì‹œ Stateì—ì„œ ìë™ ê°€ì ¸ì˜´, Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    
    Returns:
        Dict: {
            "artifacts": [
                {
                    "id": "artifact_001",
                    "artifact_type": "usb_files",
                    "device_name": "Samsung",
                    "file_name": "secret.pdf",
                    ...
                }
            ],
            "message": "18ê°œ ê²€ìƒ‰ ì™„ë£Œ",
            "metadata": {
                "requested": 20,
                "returned": 18,
                "filtered_from": 150,
                "limited": False,
                "threshold": 0.7,
                "filter_types": ["usb_files"],
                "filter_datetime_start": "2024-01-15T00:00:00",
                "filter_datetime_end": "2024-01-15T12:00:00",
                "filter_used": True
            }
        }
    
    Note:
        - ìµœëŒ€ 300ê°œ ê²°ê³¼ ì œí•œ (í† í° ì œí•œ)
        - í•„í„°ë¥¼ ì‚¬ìš©í•˜ë©´ ê²€ìƒ‰ ì†ë„ ëŒ€í­ í–¥ìƒ
        - ê²°ê³¼ ê°œìˆ˜ê°€ ì ìœ¼ë©´ í•„í„° ì¡°ê±´ ì™„í™” ê¶Œì¥
    """
    print("--- ğŸ” Tool: 2ë‹¨ê³„ ê²€ìƒ‰ ì‹¤í–‰ ---")
    
    # collection_nameê³¼ db_configê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ToolContextì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if collection_name is None:
        collection_name = ToolContext.get_collection_name()
    if db_config is None:
        db_config = ToolContext.get_db_config()
    
    try:
        # db_configê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        if db_config is None:
            config = DEFAULT_DB_CONFIG
        else:
            from workflow.database import VectorDBConfig
            
            # dictë¥¼ VectorDBConfigë¡œ ë³€í™˜
            config = VectorDBConfig(
                db_type=db_config.get("db_type", "chroma"),
                embedding_model=db_config.get("embedding_model", "gemini-embedding-001"),
                embedding_provider=db_config.get("embedding_provider", "google"),
                persist_directory=db_config.get("persist_directory", "./chroma")
            )
        
        # ë²¡í„° DB ì¬ìƒì„± (stateì—ì„œ ì „ë‹¬ëœ ì„¤ì • ì‚¬ìš©)
        vectorstore = create_vectorstore(
            config=config,
            collection_name=collection_name
        )
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        query_text = structured_query.get("query_text", "")
        
        # 1ì°¨ í•„í„°ë§ íŒŒë¼ë¯¸í„° (Optional)
        filter_types = structured_query.get("filter_artifact_types", [])
        filter_datetime_start = structured_query.get("filter_datetime_start")
        filter_datetime_end = structured_query.get("filter_datetime_end")
        
        # 2ì°¨ ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        requested_max = structured_query.get("max_results", 300)
        max_results = int(requested_max)  # ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        similarity_threshold = structured_query.get("similarity_threshold", 0.5)
        
        # ğŸ”’ í† í° ì œí•œ ì•ˆì „ ì¥ì¹˜: MAX_SEARCH_RESULTSë¡œ ì œí•œ
        limited = False
        if max_results > MAX_SEARCH_RESULTS:
            print(f"  âš ï¸  max_results {max_results}ëŠ” ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. {MAX_SEARCH_RESULTS}ë¡œ ì œí•œí•©ë‹ˆë‹¤.")
            max_results = MAX_SEARCH_RESULTS
            limited = True
        elif max_results < 1:
            print(f"  âš ï¸  max_results {max_results}ëŠ” ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. 1ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            max_results = 1
        
        # ğŸ”¹ 1ì°¨ í•„í„°: ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„±
        filter_conditions = []
        
        # artifact_type í•„í„° (ì •í™• ì¼ì¹˜)
        if filter_types:
            filter_conditions.append({"artifact_type": {"$in": filter_types}})
        
        # âœ… datetime í•„í„°ë¥¼ timestamp(ìˆ«ì)ë¡œ ë³€í™˜í•˜ì—¬ Chroma DBì—ì„œ ì§ì ‘ í•„í„°ë§
        # ChromaDBëŠ” í•˜ë‚˜ì˜ í•„ë“œì— ì—¬ëŸ¬ ì—°ì‚°ìë¥¼ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë¶„ë¦¬
        if filter_datetime_start or filter_datetime_end:
            if filter_datetime_start:
                start_ts = datetime_to_timestamp(filter_datetime_start)
                if start_ts is not None:
                    filter_conditions.append({"timestamp": {"$gte": start_ts}})
            
            if filter_datetime_end:
                end_ts = datetime_to_timestamp(filter_datetime_end)
                if end_ts is not None:
                    filter_conditions.append({"timestamp": {"$lte": end_ts}})
        
        # Chroma DB í•„í„° êµ¬ì„±: ì¡°ê±´ì´ ì—¬ëŸ¬ ê°œë©´ $andë¡œ ë¬¶ê¸°
        if len(filter_conditions) == 0:
            metadata_filter = None
            print(f"  ğŸ” 1ì°¨ í•„í„°: ì—†ìŒ (ì „ì²´ ê²€ìƒ‰)")
        elif len(filter_conditions) == 1:
            metadata_filter = filter_conditions[0]
            print(f"  ğŸ” 1ì°¨ í•„í„° ì ìš©: {metadata_filter}")
        else:
            metadata_filter = {"$and": filter_conditions}
            print(f"  ğŸ” 1ì°¨ í•„í„° ì ìš© (ë‹¤ì¤‘ ì¡°ê±´): {len(filter_conditions)}ê°œ ì¡°ê±´")
        
        # ğŸ”¹ 2ì°¨ ê²€ìƒ‰: ìœ ì‚¬ë„ ê²€ìƒ‰ (1ì°¨ í•„í„° ê²°ê³¼ ëŒ€ìƒ)
        search_k = int(max_results * 2)  # ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        
        # ThreadPoolExecutor í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ê²€ìƒ‰ ìˆ˜í–‰
        try:
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ìƒˆë¡œìš´ ë£¨í”„ ìƒì„±
            loop = asyncio.get_event_loop()
        except RuntimeError:
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        # ë™ê¸° ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰
        results_with_scores = vectorstore.similarity_search_with_score(
            query=query_text,
            k=search_k,
            filter=metadata_filter
        )
        
        # ê²€ìƒ‰ í†µê³„
        initial_count = len(results_with_scores)
        print(f"  ğŸ“Š 1ì°¨ í•„í„° í†µê³¼: {initial_count}ê°œ")
        
        # ğŸ”¹ ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§ (ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬í•¨)
        # ChromaëŠ” ê±°ë¦¬(distance)ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, ì„ê³„ê°’ë³´ë‹¤ ì‘ì€ ê²ƒë§Œ ì„ íƒ
        filtered_results = [
            (doc, score) 
            for doc, score in results_with_scores 
            if score <= (1.0 - similarity_threshold)  # ê±°ë¦¬ â†’ ìœ ì‚¬ë„ ë³€í™˜
        ]
        
        # ğŸ”¹ ìµœëŒ€ ê°œìˆ˜ë¡œ ì œí•œ
        filtered_results = filtered_results[:max_results]
        results = [doc for doc, score in filtered_results]
        
        # ê²€ìƒ‰ í†µê³„
        filtered_count = len(results)
        
        print(f"  ğŸ“Š 2ì°¨ í•„í„° (ìœ ì‚¬ë„ {similarity_threshold}) í†µê³¼: {filtered_count}ê°œ")
        if limited:
            print(f"  âš ï¸  í† í° ì œí•œìœ¼ë¡œ {requested_max}ê°œ â†’ {max_results}ê°œë¡œ ì œí•œë¨")
        
        # Documentë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (page_content íŒŒì‹±)
        artifacts = []
        for doc in results:
            # page_content íŒŒì‹±í•˜ì—¬ data ì¶”ì¶œ (ëª¨ë‘ ë¬¸ìì—´)
            artifact_dict = parse_page_content(doc.page_content)
            
            # IDì™€ artifact_typeì„ dataì— ì¶”ê°€
            artifact_dict["id"] = doc.metadata.get("artifact_id", "unknown")
            artifact_dict["artifact_type"] = doc.metadata.get("artifact_type", "unknown")
            
            artifacts.append(artifact_dict)
        
        # ğŸ¯ ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
        if limited:
            message = f"âœ… {filtered_count}ê°œ ê²€ìƒ‰ ì™„ë£Œ (ìš”ì²­: {requested_max}ê°œ â†’ í† í° ì œí•œìœ¼ë¡œ {max_results}ê°œë¡œ ì œí•œë¨)"
        elif filtered_count < requested_max:
            message = f"âœ… {filtered_count}ê°œ ê²€ìƒ‰ ì™„ë£Œ (ìš”ì²­: {requested_max}ê°œ, ìœ ì‚¬ë„ ì„ê³„ê°’ {similarity_threshold}ë¡œ í•„í„°ë§)"
        else:
            message = f"âœ… {filtered_count}ê°œ ê²€ìƒ‰ ì™„ë£Œ"
        
        print(f"  {message}")
        
        # ğŸ¯ ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„° í•¨ê»˜ ë°˜í™˜
        return {
            "artifacts": artifacts,  # List[Dict[str, str]] - ID í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
            "message": message,
            "metadata": {
                "requested": requested_max,
                "returned": filtered_count,
                "filtered_from": initial_count,
                "limited": limited,
                "threshold": similarity_threshold,
                "filter_types": filter_types or [],
                "filter_datetime_start": filter_datetime_start,
                "filter_datetime_end": filter_datetime_end,
                "filter_used": len(filter_conditions) > 0
            }
        }
        
    except Exception as e:
        error_msg = f"ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {type(e).__name__} - {str(e)}"
        print(f"  âŒ {error_msg}")
        
        # ì‹¤íŒ¨ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return {
            "artifacts": [],
            "message": f"âŒ {error_msg}",
            "metadata": {
                "requested": structured_query.get("max_results", 10),
                "returned": 0,
                "filtered_from": 0,
                "limited": False,
                "threshold": structured_query.get("similarity_threshold", 0.5),
                "filter_types": structured_query.get("filter_artifact_types", []) or []
            }
        }


@tool
def search_artifacts_tool(natural_language_goal: str) -> Dict:
    """
    ë””ì§€í„¸ í¬ë Œì‹ ì•„í‹°íŒ©íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (í†µí•© ë„êµ¬)
    
    [í†µí•© ê¸°ëŠ¥]
    - ìì—°ì–´ ê²€ìƒ‰ ëª©í‘œ ì…ë ¥ â†’ ìë™ìœ¼ë¡œ ìµœì í™”ëœ ì¿¼ë¦¬ ìƒì„± (AI ê¸°ë°˜)
    - 2ë‹¨ê³„ ê²€ìƒ‰ ì¦‰ì‹œ ì‹¤í–‰ (ë©”íƒ€ë°ì´í„° í•„í„° + ë²¡í„° ìœ ì‚¬ë„)
    - ê²€ìƒ‰ ê²°ê³¼ ì§ì ‘ ë°˜í™˜ (í•œ ë²ˆì˜ ë„êµ¬ í˜¸ì¶œë¡œ ì™„ë£Œ)
    
    [ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤]
    ë‚´ë¶€ 1ë‹¨ê³„: ì¿¼ë¦¬ ìµœì í™” (ìë™)
       - LLMì´ ê²€ìƒ‰ ëª©í‘œ ë¶„ì„
       - ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ìµœì  í•„í„° ìë™ ê²°ì •
       - artifact_type, datetime, í•„í„° ìƒì„±
    
    ë‚´ë¶€ 2ë‹¨ê³„: ì‹¤ì œ ê²€ìƒ‰ (ìë™)
       - 1ì°¨: ë©”íƒ€ë°ì´í„° í•„í„°ë§
       - 2ì°¨: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
       - ê²°ê³¼ ë°˜í™˜
    
    [ê²€ìƒ‰ íŒ]
    êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í• ìˆ˜ë¡ ì •í™•í•œ ê²°ê³¼:
    - "2024ë…„ 1ì›” 15ì¼ ì˜¤ì „ USBë¡œ ì „ì†¡ëœ ë¬¸ì„œ íŒŒì¼" âœ…
    - "ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ ê¸°ë¡ì—ì„œ .exe íŒŒì¼" âœ…
    - "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒŒì¼" âŒ (ë„ˆë¬´ ê´‘ë²”ìœ„)
    
    [ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°]
    - artifacts: ì‹¤ì œ ê²€ìƒ‰ëœ ì•„í‹°íŒ©íŠ¸ ë¦¬ìŠ¤íŠ¸
    - message: ê²€ìƒ‰ ì™„ë£Œ ë©”ì‹œì§€
    - metadata: ê²€ìƒ‰ í†µê³„ (ê°œìˆ˜, í•„í„° ì ìš© ì—¬ë¶€ ë“±)
    
    Args:
        natural_language_goal: êµ¬ì²´ì ì¸ ê²€ìƒ‰ ëª©í‘œ (ìì—°ì–´)
    
    Returns:
        Dict: {
            "artifacts": [
                {
                    "id": "artifact_001",
                    "artifact_type": "usb_files",
                    "device_name": "Samsung",
                    "file_name": "secret.pdf",
                    ...
                }
            ],
            "message": "18ê°œ ê²€ìƒ‰ ì™„ë£Œ",
            "metadata": {
                "requested": 20,
                "returned": 18,
                "filtered_from": 150,
                "limited": False,
                "threshold": 0.7,
                "filter_types": ["usb_files"]
            }
        }
    
    Examples:
        >>> search_artifacts_tool("USBë¡œ ì „ì†¡ëœ ê¸°ë°€ ë¬¸ì„œ")
        {'artifacts': [...], 'message': '5ê°œ ê²€ìƒ‰ ì™„ë£Œ'}
        
        >>> search_artifacts_tool("2024-01-15 ì˜¤ì „ ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ ê¸°ë¡")
        {'artifacts': [...], 'message': '12ê°œ ê²€ìƒ‰ ì™„ë£Œ'}
        
        >>> search_artifacts_tool("ì´ë ¥ì„œ ê´€ë ¨ ì›¹ì‚¬ì´íŠ¸ ì ‘ì† ê¸°ë¡")
        {'artifacts': [...], 'message': '8ê°œ ê²€ìƒ‰ ì™„ë£Œ'}
    
    Note:
        - ìµœëŒ€ 300ê°œ ê²°ê³¼ ì œí•œ
        - ê²€ìƒ‰ ê²°ê³¼ê°€ ì ìœ¼ë©´ ë” ê´‘ë²”ìœ„í•œ í‚¤ì›Œë“œë¡œ ì¬ì‹œë„ ê¶Œì¥
        - ì‹œê°„, íƒ€ì… í•„í„°ë¥¼ í¬í•¨í•˜ë©´ ê²€ìƒ‰ ì†ë„ ëŒ€í­ í–¥ìƒ
    """
    print("--- ğŸ” Tool: í†µí•© ê²€ìƒ‰ ì‹¤í–‰ ---")
    
    # Step 1: ì¿¼ë¦¬ ìƒì„± (ë‚´ë¶€)
    print("  ğŸ§  Step 1/2: ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ì¤‘...")
    try:
        query_result = query_planner_tool.invoke({"natural_language_goal": natural_language_goal})
        print(f"  âœ… ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"  âŒ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return {
            "artifacts": [],
            "message": f"âŒ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}",
            "metadata": {"returned": 0}
        }
    
    # Step 2: ê²€ìƒ‰ ì‹¤í–‰ (ë‚´ë¶€)
    print("  ğŸ” Step 2/2: ì•„í‹°íŒ©íŠ¸ ê²€ìƒ‰ ì¤‘...")
    try:
        search_result = artifact_search_tool.invoke({
            "structured_query": query_result,
            "collection_name": None,  # ToolContextì—ì„œ ìë™ ê°€ì ¸ì˜´
            "db_config": None
        })
        
        artifacts_count = len(search_result.get("artifacts", []))
        print(f"  âœ… í†µí•© ê²€ìƒ‰ ì™„ë£Œ: {artifacts_count}ê°œ ë°œê²¬")
        
        return search_result
        
    except Exception as e:
        print(f"  âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {
            "artifacts": [],
            "message": f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}",
            "metadata": {"returned": 0}
        }


# ì›¹ ê²€ìƒ‰ ë„êµ¬ (Tavily)
web_search_tool = TavilySearch(max_results=3)
web_search_tool.name = "web_search_tool"
web_search_tool.description = """
ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ë³´ì•ˆ ìœ„í˜‘, ê³µê²© ê¸°ë²•, CVE ì •ë³´ ë“± 
ì™¸ë¶€ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
"""


# ëª¨ë“  ë„êµ¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ export
agent_tools = [
    search_artifacts_tool,  # í†µí•© ê²€ìƒ‰ ë„êµ¬ (query_planner + artifact_search)
    web_search_tool
]
