"""
ì›Œí¬í”Œë¡œìš° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° í¬ë§·íŒ…
- ì—ëŸ¬ ì‘ë‹µ ìƒì„±
"""
import os
import logging
from dotenv import load_dotenv
from datetime import date, datetime
from typing import Any, Dict, List, Optional, Union
from workflow.database import VectorDBConfig, get_chroma_client

env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
load_dotenv(env_path)

from langchain.chat_models import init_chat_model

logger = logging.getLogger(__name__)
llm_small = init_chat_model("google_genai:gemini-2.5-flash-lite", temperature=0)
llm_medium = init_chat_model("google_genai:gemini-2.5-flash", temperature=0)
llm_large = init_chat_model("google_genai:gemini-2.5-pro", temperature=0)


# --------------------------------------------------------------------------
# ì˜ˆì™¸ í´ë˜ìŠ¤ (tools.pyì—ì„œ ì‚¬ìš©)
# --------------------------------------------------------------------------

class ChromaDBError(Exception):
    """ChromaDB ê´€ë ¨ ê¸°ë³¸ ì—ëŸ¬"""
    pass


class CollectionNotFoundError(ChromaDBError):
    """ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"""
    def __init__(self, collection_name: str):
        super().__init__(f"ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        self.collection_name = collection_name


class MetadataExtractionError(ChromaDBError):
    """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"""
    pass


# --------------------------------------------------------------------------
# ë©”íƒ€ë°ì´í„° ê´€ë ¨ í•¨ìˆ˜
# --------------------------------------------------------------------------

def get_metadata_info(
    collection_name: str,
    config: Union[None, dict, VectorDBConfig] = None
) -> Dict:
    """
    ë²¡í„° DBì—ì„œ ë©”íƒ€ë°ì´í„° í†µê³„ ì •ë³´ ì¶”ì¶œ
    (artifact_types, datetime_range, total_count)
    """
    try:
        from workflow.database import normalize_config
        
        # Config ì •ê·œí™”
        db_config = normalize_config(config)
        
        # ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        client = get_chroma_client(db_config)
        
        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
        try:
            collection = client.get_collection(name=collection_name)
        except Exception as e:
            raise CollectionNotFoundError(collection_name) from e
        
        # ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        results = collection.get(include=["metadatas"])
        metadatas = results.get("metadatas", [])
        
        if not metadatas:
            logger.warning("ì»¬ë ‰ì…˜ '%s'ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤", collection_name)
            return {
                "artifact_types": [],
                "datetime_range": {"earliest": None, "latest": None},
                "total_count": 0
            }
        
        # artifact_type ìˆ˜ì§‘
        artifact_types = set()
        datetimes = []
        
        for meta in metadatas:
            if meta.get("artifact_type"):
                artifact_types.add(meta["artifact_type"])
            if meta.get("datetime"):
                datetimes.append(meta["datetime"])
        
        result = {
            "artifact_types": sorted(list(artifact_types)),
            "datetime_range": {
                "earliest": min(datetimes) if datetimes else None,
                "latest": max(datetimes) if datetimes else None
            },
            "total_count": len(metadatas)
        }
        
        logger.info(
            "ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: %dê°œ ì•„í‹°íŒ©íŠ¸, %dê°œ íƒ€ì…",
            result["total_count"],
            len(result["artifact_types"])
        )
        
        return result
        
    except CollectionNotFoundError:
        raise
    except Exception as e:
        logger.debug("ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ (ë‚´ë¶€): %s", e, exc_info=True)
        raise MetadataExtractionError(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}") from e


def format_metadata_section(metadata_info: dict) -> str:
    """ë©”íƒ€ë°ì´í„° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    total_count = metadata_info.get('total_count', 0)
    artifact_types = metadata_info.get('artifact_types', [])
    datetime_range = metadata_info.get('datetime_range', {})
    
    return f"""**ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„°:**
- ì „ì²´ ì•„í‹°íŒ©íŠ¸ ìˆ˜: {total_count:,}ê°œ
- ì‚¬ìš© ê°€ëŠ¥í•œ Artifact Types: {artifact_types}
- ì‹œê°„ ë²”ìœ„: {datetime_range.get('earliest')} ~ {datetime_range.get('latest')}"""


# --------------------------------------------------------------------------
# ì—ëŸ¬ ì‘ë‹µ ìƒì„±
# --------------------------------------------------------------------------

def create_search_error_response(error_msg: str, structured_query: Dict) -> Dict:
    """ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ í‘œì¤€ ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
    return {
        "artifacts": [],
        "message": f"âŒ {error_msg}",
        "metadata": {
            "requested": structured_query.get("max_results", 10),
            "returned": 0,
            "filtered_from": 0,
            "limited": False,
            "threshold": structured_query.get("similarity_threshold", 0.5),
            "filter_types": structured_query.get("filter_artifact_types", []) or []
        }
    }
#
#
#

def calculate_optimal_chunk_size(total_artifacts: int, target_chunks: int = 100) -> int:
    """
    ì•„í‹°íŒ©íŠ¸ ì´ ê°œìˆ˜ì— ë”°ë¼ ìµœì ì˜ ì²­í¬ ì‚¬ì´ì¦ˆ ê³„ì‚°
    
    Args:
        total_artifacts: ì „ì²´ ì•„í‹°íŒ©íŠ¸ ê°œìˆ˜
        target_chunks: ëª©í‘œ ì²­í¬ ê°œìˆ˜ (ê¸°ë³¸ 100ê°œ)
        
    Returns:
        ìµœì í™”ëœ ì²­í¬ ì‚¬ì´ì¦ˆ
    """
    # ëª©í‘œ ì²­í¬ ê°œìˆ˜ë¡œ ë‚˜ëˆˆ ê°’
    calculated_size = total_artifacts // target_chunks
    
    # ìµœì†Œ/ìµœëŒ€ ì œí•œ ì„¤ì •
    min_chunk_size = 500   # ë„ˆë¬´ ì‘ìœ¼ë©´ ë¹„íš¨ìœ¨
    max_chunk_size = 2000  # ë„ˆë¬´ í¬ë©´ í† í° ì´ˆê³¼ ìœ„í—˜
    
    # ë²”ìœ„ ë‚´ë¡œ ì¡°ì •
    optimal_size = max(min_chunk_size, min(calculated_size, max_chunk_size))
    
    # ì‹¤ì œ ì²­í¬ ê°œìˆ˜ ê³„ì‚°
    actual_chunks = (total_artifacts + optimal_size - 1) // optimal_size
    
    print(f"ğŸ“Š ì²­í¬ ì‚¬ì´ì¦ˆ ìµœì í™” ê²°ê³¼:")
    print(f"  - ì „ì²´ ì•„í‹°íŒ©íŠ¸: {total_artifacts:,}ê°œ")
    print(f"  - ì²­í¬ ì‚¬ì´ì¦ˆ: {optimal_size}ê°œ")
    print(f"  - ì˜ˆìƒ ì²­í¬ ê°œìˆ˜: {actual_chunks}ê°œ")
    print(f"  - Map ë‹¨ê³„ LLM í˜¸ì¶œ: {actual_chunks}ë²ˆ")
    print(f"  - ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: ~{actual_chunks * 2.5:.0f}ì´ˆ (ì•½ {actual_chunks * 2.5 / 60:.1f}ë¶„)")
    
    return optimal_size


# --------------------------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# --------------------------------------------------------------------------

def convert_datetime_to_str(obj: Any) -> Any:
    """
    ì¬ê·€ì ìœ¼ë¡œ ê°ì²´ ë‚´ì˜ ëª¨ë“  datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.
    
    Args:
        obj: ë³€í™˜í•  ê°ì²´ (dict, list, datetime ë“±)
    
    Returns:
        datetimeì´ ë¬¸ìì—´ë¡œ ë³€í™˜ëœ ê°ì²´
    """
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {key: convert_datetime_to_str(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_datetime_to_str(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_datetime_to_str(item) for item in obj)
    else:
        return obj


def datetime_to_timestamp(dt: Any) -> Optional[float]:
    """
    Datetime ê°ì²´ë¥¼ UTC íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    pandas Timestamp, ISO ë¬¸ìì—´, datetime ê°ì²´ ëª¨ë‘ ì§€ì›
    """
    if dt is None:
        return None
    
    try:
        # pandas Timestamp ì²˜ë¦¬
        if hasattr(dt, 'timestamp'):
            return float(dt.timestamp())
        
        if isinstance(dt, str):
            # ìŠ¬ë˜ì‹œ êµ¬ë¶„ìë¥¼ ëŒ€ì‹œë¡œ ë³€ê²½
            dt = dt.replace('/', '-')
            
            try:
                dt = datetime.fromisoformat(dt.replace('Z', '+00:00'))
            except ValueError:
                from dateutil import parser
                dt = parser.parse(dt)
        
        if isinstance(dt, datetime):
            return dt.timestamp()
        elif isinstance(dt, date):
            dt = datetime.combine(dt, datetime.min.time())
            return dt.timestamp()
        
        return None
    except Exception as e:
        print(f"  âš ï¸  Datetime ë³€í™˜ ì‹¤íŒ¨: {e} (ê°’: {dt})")
        return None


def timestamp_to_datetime(ts: Optional[float]) -> Optional[str]:
    """UTC íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if ts is None:
        return None
    
    try:
        return datetime.fromtimestamp(ts).isoformat()
    except Exception as e:
        print(f"  âš ï¸  Timestamp ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None


def chunk_artifacts(artifacts: List[dict], chunk_size: int = 50) -> List[List[dict]]:
    """ì•„í‹°íŒ©íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    return [artifacts[i:i+chunk_size] for i in range(0, len(artifacts), chunk_size)]